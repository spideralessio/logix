{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5779dbb3-fe07-4a91-9802-25b8ae22870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from torch_geometric.data import Data, Batch\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import (\n",
    "    GCNConv,\n",
    "    GINConv,\n",
    "    global_add_pool,\n",
    "    global_max_pool,\n",
    "    global_mean_pool\n",
    ")\n",
    "from torch_geometric.utils import k_hop_subgraph, subgraph\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "from syn_dataset import SynGraphDataset\n",
    "from spmotif_dataset import *\n",
    "from utils import *\n",
    "from model import GIN\n",
    "from train_baseline import test_epoch\n",
    "from tell_sigmoid import LogicalLayer\n",
    "\n",
    "from graphxai.explainers._base import _BaseExplainer\n",
    "from graphxai.utils import Explanation, node_mask_from_edge_mask\n",
    "from pgexplainer import PGExplainer\n",
    "from gstarx import GStarX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c0a18-7837-4e3e-b598-4be5deb0dcc1",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea57f51a-5ba4-4e02-8dd2-58fee852983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_baseline_path(dataset_name):\n",
    "    l = glob.glob(f'results/{dataset_name}/*/results.json')\n",
    "    fl = [json.load(open(f)) for f in l]\n",
    "    df = pd.DataFrame(fl)\n",
    "    if df.shape[0] == 0: return None\n",
    "    df['fname'] = l\n",
    "    df = df.sort_values(by=['val_acc_mean', 'val_acc_std', 'test_acc_std'], ascending=[True,False,False])\n",
    "    print(df)\n",
    "    fname = df.iloc[-1]['fname']\n",
    "    fname = fname.replace('/results.json', '')\n",
    "    return fname\n",
    "\n",
    "def inverse_sigmoid(x):\n",
    "    \"\"\"Computes the inverse of the sigmoid function (logit function).\"\"\"\n",
    "    return torch.log(x / (1 - x))\n",
    "\n",
    "@torch.no_grad()\n",
    "def find_logic_rules(w, t_in, t_out, activations=None, max_rule_len=10, max_rules=100, min_support=1):\n",
    "    w = w.clone()\n",
    "    t_in = t_in.clone()\n",
    "    t_out = t_out.clone()\n",
    "    t_out = t_out.item()\n",
    "    ordering_scores = w\n",
    "    sorted_idxs = torch.argsort(ordering_scores, 0, descending=True)\n",
    "    mask = w > 1e-5\n",
    "    if activations is not None:\n",
    "        mask = mask & (activations.sum(0) >= min_support)\n",
    "    total_result = set()\n",
    "\n",
    "    # Filter and sort indices based on the mask\n",
    "    idxs_to_visit = sorted_idxs[mask[sorted_idxs]]\n",
    "    if idxs_to_visit.numel() == 0:\n",
    "        return total_result\n",
    "\n",
    "    # Sort weights based on the filtered indices\n",
    "    sorted_weights = w[idxs_to_visit]\n",
    "    current_combination = []\n",
    "    result = set()\n",
    "\n",
    "    def find_logic_rules_recursive(index, current_sum):\n",
    "        # Stop if the maximum number of rules has been reached\n",
    "        if len(result) >= max_rules:\n",
    "            return\n",
    "\n",
    "        if len(current_combination) > max_rule_len:\n",
    "            return\n",
    "\n",
    "        # Check if the current combination satisfies the condition\n",
    "        if current_sum >= t_out:\n",
    "            c = idxs_to_visit[current_combination].cpu().detach().tolist()\n",
    "            c = tuple(sorted(c))\n",
    "            result.add(c)\n",
    "            return\n",
    "\n",
    "        # Prune if remaining weights can't satisfy t_out\n",
    "        remaining_max_sum = current_sum + sorted_weights[index:].sum()\n",
    "        if remaining_max_sum < t_out:\n",
    "            return\n",
    "\n",
    "        # Explore further combinations\n",
    "        for i in range(index, idxs_to_visit.shape[0]):\n",
    "            # Prune based on activations if provided\n",
    "            if activations is not None and len(current_combination) > 0 and activations[:, idxs_to_visit[current_combination + [i]]].all(-1).sum().item() < min_support:\n",
    "                continue\n",
    "\n",
    "            current_combination.append(i)\n",
    "            find_logic_rules_recursive(i + 1, current_sum + sorted_weights[i])\n",
    "            current_combination.pop()\n",
    "\n",
    "    # Start the recursive process\n",
    "    find_logic_rules_recursive(0, 0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_rules(self, feature=None, activations=None, max_rule_len=float('inf'), max_rules=100, min_support=1, out_threshold=0.5):\n",
    "    ws = self.weight\n",
    "    t_in = self.phi_in.t\n",
    "    t_out = -self.b + inverse_sigmoid(torch.tensor(out_threshold))\n",
    "\n",
    "    rules = []\n",
    "    if feature is None:\n",
    "        features = range(self.out_features)\n",
    "    else:\n",
    "        features = [feature]\n",
    "    for i in features:\n",
    "        w = ws[i].to('cpu')\n",
    "        ti = t_in.to('cpu')\n",
    "        to = t_out[i].to('cpu')\n",
    "        rules.append(find_logic_rules(w, ti, to, activations, max_rule_len, max_rules, min_support))\n",
    "\n",
    "    return rules\n",
    "\n",
    "\n",
    "\n",
    "def get_blues_color(value):\n",
    "    cmap = plt.get_cmap(\"Blues\")  # Get the Blues colormap\n",
    "    return cmap(value)  # Return the RGBA color\n",
    "\n",
    "def plot_activations(batch_ids, batch, attr, soft=False):\n",
    "    if type(batch_ids) != list:\n",
    "        batch_ids = [batch_ids]\n",
    "    if soft: attr = (attr-attr.min() + 1e-6)/(attr.max()-attr.min()+1e-6)\n",
    "    fig, axs = plt.subplots(1, len(batch_ids), figsize=(16*len(batch_ids), 8))\n",
    "    if type(axs) != np.ndarray: axs = np.array([axs])\n",
    "    for i, batch_id in enumerate(batch_ids):\n",
    "        node_mask = batch.batch == batch_id  # Get nodes where batch == 0\n",
    "        node_indices = torch.nonzero(node_mask, as_tuple=True)[0]\n",
    "        \n",
    "        subgraph_edge_mask = (batch.batch[batch.edge_index[0]] == batch_id) & \\\n",
    "                             (batch.batch[batch.edge_index[1]] == batch_id)\n",
    "        subgraph_edges = batch.edge_index[:, subgraph_edge_mask]\n",
    "        \n",
    "        node_mapping = {old_idx.item(): new_idx for new_idx, old_idx in enumerate(node_indices)}\n",
    "        remapped_edges = torch.tensor([[node_mapping[e.item()] for e in edge] for edge in subgraph_edges.T])\n",
    "        \n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(remapped_edges.numpy())\n",
    "        \n",
    "        nx.set_node_attributes(G, {v: k for k, v in node_mapping.items()}, \"original_id\")\n",
    "        \n",
    "        node_colors = []\n",
    "        node_borders = []\n",
    "        \n",
    "        for node in G.nodes:\n",
    "            node_colors.append(get_blues_color(attr[batch.batch==batch_id][node]))  # Fill color\n",
    "            \n",
    "        \n",
    "        pos = nx.kamada_kawai_layout(G) \n",
    "        \n",
    "        nx.draw(\n",
    "            G, pos,\n",
    "            node_color=node_colors,\n",
    "            edgecolors=node_borders,  # Border colors\n",
    "            node_size=700,\n",
    "            with_labels=False,\n",
    "            ax = axs[i]\n",
    "        )\n",
    "        \n",
    "        axs[i].set_title(f\"Class = {batch.y[batch_id]}\")\n",
    "    plt.show()\n",
    "\n",
    "def calculate_fidelity(data, node_mask, model, remove_nodes=True, top_k=None):\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    data = data.to(device)\n",
    "\n",
    "    # Compute sparsity\n",
    "    total_nodes = data.x.shape[0]\n",
    "    sparsity = 1 - node_mask.sum().item() / total_nodes if total_nodes > 0 else 0\n",
    "\n",
    "    # Get original predictions\n",
    "    original_pred = model(data.x.float(), data.edge_index)\n",
    "    # original_pred = F.softmax(original_pred, dim=1)\n",
    "    label = original_pred.argmax(-1).item()\n",
    "    \n",
    "    if remove_nodes:\n",
    "        masked_edge_index, _ = subgraph(node_mask == 0, edge_index=data.edge_index, num_nodes=data.x.size(0), relabel_nodes=True)\n",
    "        masked_pred = model(data.x[node_mask == 0], masked_edge_index)\n",
    "    else:\n",
    "        masked_x = data.x.clone()\n",
    "        masked_x[node_mask==1] = 0\n",
    "        masked_pred = model(masked_x, data.edge_index)\n",
    "\n",
    "    if remove_nodes:\n",
    "        masked_edge_index, _ = subgraph(node_mask == 1, edge_index=data.edge_index, num_nodes=data.x.size(0), relabel_nodes=True)\n",
    "        retained_pred = model(data.x[node_mask == 1], masked_edge_index)\n",
    "    else:\n",
    "        masked_x = data.x.clone()\n",
    "        masked_x[node_mask==0] = 0\n",
    "        retained_pred = model(masked_x, data.edge_index)\n",
    "\n",
    "    inv_fidelity = (original_pred.argmax(-1) != \n",
    "                                 retained_pred.argmax(-1)).float().item()\n",
    "\n",
    "    fidelity = (original_pred.argmax(-1)  != \n",
    "                                 masked_pred.argmax(-1) ).float().item()\n",
    "\n",
    "    n_fidelity = inv_fidelity*sparsity\n",
    "    n_inv_fidelity = inv_fidelity*(1-sparsity)\n",
    "    \n",
    "    hfidelity = ((1+n_fidelity) * (1-n_inv_fidelity)) / (2 + n_fidelity - n_inv_fidelity) if (1 + n_fidelity - n_inv_fidelity) != 0 else 0\n",
    "\n",
    "    return {\n",
    "        \"Fidelity\": fidelity,\n",
    "        \"InvFidelity\": inv_fidelity,\n",
    "        \"HFidelity\": hfidelity\n",
    "    }\n",
    "\n",
    "\n",
    "def calculate_fidelity_topk(data, node_soft_mask, model, top_k, remove_nodes=True):\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    data = data.to(device)\n",
    "\n",
    "    # Compute sparsity\n",
    "    total_nodes = data.x.shape[0]\n",
    "\n",
    "    # Get original predictions\n",
    "    original_pred = model(data.x.float(), data.edge_index)\n",
    "    # original_pred = F.softmax(original_pred, dim=1)\n",
    "    label = original_pred.argmax(-1).item()\n",
    "\n",
    "    \n",
    "\n",
    "    node_mask = torch.zeros_like(node_soft_mask)\n",
    "    node_mask[torch.topk(node_soft_mask, top_k).indices] = 1\n",
    "    \n",
    "    if remove_nodes:\n",
    "        masked_edge_index, _ = subgraph(node_mask == 0, edge_index=data.edge_index, num_nodes=data.x.size(0), relabel_nodes=True)\n",
    "        masked_pred = model(data.x[node_mask == 0], masked_edge_index)\n",
    "    else:\n",
    "        masked_x = data.x.clone()\n",
    "        masked_x[node_mask==1] = 0\n",
    "        masked_pred = model(masked_x, data.edge_index)\n",
    "\n",
    "    node_mask = torch.zeros_like(node_soft_mask)\n",
    "    node_mask[torch.topk(node_soft_mask, total_nodes-top_k).indices] = 1\n",
    "    \n",
    "    if remove_nodes:\n",
    "        masked_edge_index, _ = subgraph(node_mask == 1, edge_index=data.edge_index, num_nodes=data.x.size(0), relabel_nodes=True)\n",
    "        retained_pred = model(data.x[node_mask == 1], masked_edge_index)\n",
    "    else:\n",
    "        masked_x = data.x.clone()\n",
    "        masked_x[node_mask==0] = 0\n",
    "        retained_pred = model(masked_x, data.edge_index)\n",
    "\n",
    "    inv_fidelity = (original_pred.argmax(-1) != \n",
    "                                 retained_pred.argmax(-1)).float().item()\n",
    "\n",
    "    fidelity = (original_pred.argmax(-1)  != \n",
    "                                 masked_pred.argmax(-1) ).float().item()\n",
    "    return {\n",
    "        \"Fidelity\": fidelity,\n",
    "        \"InvFidelity\": inv_fidelity,\n",
    "    }\n",
    "\n",
    "def node_imp_from_edge_imp(edge_index, n_nodes, edge_imp):\n",
    "    node_imp = torch.zeros(n_nodes)\n",
    "    for i in range(n_nodes):\n",
    "        node_imp[i] = edge_imp[(edge_index[0]==i) | (edge_index[1]==i)].mean()\n",
    "    return node_imp\n",
    "        \n",
    "def generate_hard_masks(soft_mask):\n",
    "    sparsity_levels = torch.arange(0.5,1, 0.05)\n",
    "    hard_masks = []\n",
    "    for sparsity in sparsity_levels:\n",
    "        threshold = np.percentile(soft_mask, sparsity * 100)\n",
    "        hard_mask = (soft_mask > threshold).int()\n",
    "        if hard_mask.sum() == 0:\n",
    "            hard_mask = (soft_mask > soft_mask.min()).int()\n",
    "        hard_masks.append(hard_mask)\n",
    "    return list(zip(sparsity_levels, hard_masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b1a4a6-4736-4f92-8351-1a512d4f203a",
   "metadata": {},
   "source": [
    "# Model and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95eb7207-ed39-4599-a049-0f5b4ae211f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    val_acc_mean  test_acc_mean  val_acc_std  test_acc_std  \\\n",
      "0       0.931579       0.857895     0.065877      0.055755   \n",
      "10      0.931579       0.800000     0.055755      0.064699   \n",
      "6       0.936842       0.836842     0.059752      0.083954   \n",
      "15      0.936842       0.821053     0.059752      0.066574   \n",
      "14      0.942105       0.810526     0.063012      0.105846   \n",
      "8       0.942105       0.847368     0.063012      0.083954   \n",
      "1       0.942105       0.852632     0.063012      0.073601   \n",
      "7       0.942105       0.878947     0.052338      0.092999   \n",
      "4       0.942105       0.836842     0.052338      0.080204   \n",
      "3       0.947368       0.831579     0.065643      0.069293   \n",
      "9       0.947368       0.821053     0.042974      0.083033   \n",
      "13      0.947368       0.836842     0.042974      0.063012   \n",
      "11      0.952632       0.815789     0.067720      0.083218   \n",
      "5       0.952632       0.826316     0.046084      0.078654   \n",
      "2       0.952632       0.868421     0.038835      0.071263   \n",
      "12      0.957895       0.842105     0.059752      0.070175   \n",
      "\n",
      "                                                fname  \n",
      "0   results/MUTAG/batch_size=32|dropout=0|epochs=3...  \n",
      "10  results/MUTAG/batch_size=128|dropout=0.5|epoch...  \n",
      "6   results/MUTAG/batch_size=32|dropout=0.5|epochs...  \n",
      "15  results/MUTAG/batch_size=128|dropout=0|epochs=...  \n",
      "14  results/MUTAG/batch_size=32|dropout=0|epochs=3...  \n",
      "8   results/MUTAG/batch_size=128|dropout=0|epochs=...  \n",
      "1   results/MUTAG/batch_size=128|dropout=0.5|epoch...  \n",
      "7   results/MUTAG/batch_size=128|dropout=0|epochs=...  \n",
      "4   results/MUTAG/batch_size=32|dropout=0|epochs=3...  \n",
      "3   results/MUTAG/batch_size=128|dropout=0|epochs=...  \n",
      "9   results/MUTAG/batch_size=128|dropout=0.5|epoch...  \n",
      "13  results/MUTAG/batch_size=32|dropout=0.5|epochs...  \n",
      "11  results/MUTAG/batch_size=128|dropout=0.5|epoch...  \n",
      "5   results/MUTAG/batch_size=32|dropout=0.5|epochs...  \n",
      "2   results/MUTAG/batch_size=32|dropout=0|epochs=3...  \n",
      "12  results/MUTAG/batch_size=32|dropout=0.5|epochs...  \n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'MUTAG'\n",
    "seed = 0\n",
    "results_path = os.path.join(get_best_baseline_path(dataset_name), str(seed))\n",
    "data = pickle.load(open(os.path.join(results_path, 'data.pkl'), 'rb'))\n",
    "args = json.load(open(os.path.join(results_path, 'args.json'), 'r'))\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "dataset = get_dataset(dataset_name)\n",
    "num_classes = dataset.num_classes\n",
    "num_features = dataset.num_features\n",
    "num_layers = args['num_layers']\n",
    "hidden_dim = args['hidden_dim']\n",
    "model = GIN(num_classes=num_classes, num_features=num_features, num_layers=num_layers, hidden_dim=hidden_dim, dropout=0.1)\n",
    "model.load_state_dict(torch.load(os.path.join(results_path, 'best.pt'), map_location=device))\n",
    "model = model.to(device)\n",
    "train_indices = data['train_indices']\n",
    "val_indices = data['val_indices']\n",
    "test_indices = data['test_indices']\n",
    "train_dataset = dataset[train_indices]\n",
    "val_dataset = dataset[val_indices]\n",
    "test_dataset = dataset[test_indices]\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "val_acc = test_epoch(model, val_loader, device)\n",
    "test_acc = test_epoch(model, test_loader, device)\n",
    "\n",
    "os.makedirs(f'post_hoc/{dataset_name}/{seed}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64b32e9-9a34-4d13-82a5-ad21f7c5e34d",
   "metadata": {},
   "source": [
    "# PGExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41fd8504-5c88-478c-a9dd-b01a7b85d3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 453.43it/s]\n"
     ]
    }
   ],
   "source": [
    "def explain_pg_explainer(model, data):\n",
    "    r = {\n",
    "        'data': data,\n",
    "        'pred': model(data.x.float(), data.edge_index).softmax(-1).detach().cpu().numpy(),\n",
    "        'res' : {}\n",
    "    }\n",
    "    data = data.to(device)\n",
    "    model=model.to(device)\n",
    "    pgexplainer = PGExplainer(model, explain_graph=True)\n",
    "    exp = pgexplainer.get_explanation_graph(x=data.x.float(), edge_index=data.edge_index)\n",
    "    soft_mask = node_imp_from_edge_imp(data.edge_index, data.x.shape[0], exp.edge_imp)\n",
    "    soft_mask[soft_mask!=soft_mask]=0\n",
    "    r['soft_mask'] = soft_mask\n",
    "    hard_masks = generate_hard_masks(soft_mask)\n",
    "    for sparsity, hard_mask in hard_masks:\n",
    "        sparsity=sparsity.item()\n",
    "        r['res'][sparsity] = calculate_fidelity(data, hard_mask, model)\n",
    "        r['res'][sparsity]['hard_mask'] = hard_mask\n",
    "\n",
    "    r['res_topk'] = {\n",
    "        1: calculate_fidelity_topk(data, soft_mask, model,1),\n",
    "        3: calculate_fidelity_topk(data, soft_mask, model,3),\n",
    "        5: calculate_fidelity_topk(data, soft_mask, model,5)\n",
    "    }\n",
    "    return r\n",
    "    \n",
    "pg_explainer_results = []\n",
    "for data in tqdm(test_dataset):\n",
    "    try:\n",
    "        data = data.to(device)\n",
    "        data.x = data.x.float()\n",
    "        r = explain_pg_explainer(model, data)\n",
    "        pg_explainer_results.append(r)\n",
    "    except: pass\n",
    "\n",
    "\n",
    "with open(f'post_hoc/{dataset_name}/{seed}/pgexplainer.pkl', 'wb') as f:\n",
    "    pickle.dump(pg_explainer_results, f)\n",
    "pg_explainer_results = pickle.load(open(f'post_hoc/{dataset_name}/{seed}/pgexplainer.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8743465a-f2f8-43c3-97e9-9d0c4fec6b74",
   "metadata": {},
   "source": [
    "# GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa36cfac-d4ae-42cd-af49-4f6c45a9a983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:12<00:00,  1.52it/s]\n"
     ]
    }
   ],
   "source": [
    "from graphxai.explainers import GNNExplainer\n",
    "\n",
    "def explain_gnn_explainer(model, data):\n",
    "    r = {\n",
    "        'data': data,\n",
    "        'pred': model(data.x.float(), data.edge_index).softmax(-1).detach().cpu().numpy(),\n",
    "        'res' : {}\n",
    "    }\n",
    "    data = data.to(device)\n",
    "    model=model.to(device)\n",
    "    gnnexplainer = GNNExplainer(model)\n",
    "    exp = gnnexplainer.get_explanation_graph(x=data.x.float(), edge_index=data.edge_index)\n",
    "    soft_mask = node_imp_from_edge_imp(data.edge_index, data.x.shape[0], exp.edge_imp)\n",
    "    soft_mask[soft_mask!=soft_mask]=0\n",
    "    r['soft_mask'] = soft_mask\n",
    "    hard_masks = generate_hard_masks(soft_mask)\n",
    "    for sparsity, hard_mask in hard_masks:\n",
    "        sparsity=sparsity.item()\n",
    "        r['res'][sparsity] = calculate_fidelity(data, hard_mask, model)\n",
    "        r['res'][sparsity]['hard_mask'] = hard_mask\n",
    "\n",
    "    r['res_topk'] = {\n",
    "        1: calculate_fidelity_topk(data, soft_mask, model,1),\n",
    "        3: calculate_fidelity_topk(data, soft_mask, model,3),\n",
    "        5: calculate_fidelity_topk(data, soft_mask, model,5)\n",
    "    }\n",
    "    return r\n",
    "    \n",
    "gnn_explainer_results = []\n",
    "for data in tqdm(test_dataset):\n",
    "    data = data.to(device)\n",
    "    data.x = data.x.float()\n",
    "    try:\n",
    "        r = explain_gnn_explainer(model, data)\n",
    "        gnn_explainer_results.append(r)\n",
    "    except: pass\n",
    "\n",
    "with open(f'post_hoc/{dataset_name}/{seed}/gnnexplainer.pkl', 'wb') as f:\n",
    "    pickle.dump(gnn_explainer_results, f)\n",
    "gnn_explainer_results = pickle.load(open(f'post_hoc/{dataset_name}/{seed}/gnnexplainer.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3da2e38-c91d-4f8e-b076-755b972a5581",
   "metadata": {},
   "source": [
    "# IG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "144edc63-60c4-4988-9600-c6e0211d53ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:04<00:00,  4.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from graphxai.explainers import IntegratedGradExplainer\n",
    "\n",
    "def explain_ig_explainer(model, data):\n",
    "    r = {\n",
    "        'data': data,\n",
    "        'pred': model(data.x.float(), data.edge_index).softmax(-1).detach().cpu().numpy(),\n",
    "        'res' : {}\n",
    "    }\n",
    "    data = data.to(device)\n",
    "    model=model.to(device)\n",
    "    igexplainer = IntegratedGradExplainer(model, torch.nn.CrossEntropyLoss())\n",
    "    exp = igexplainer.get_explanation_graph(x=data.x.float(), edge_index=data.edge_index, label=torch.tensor(r['pred'].argmax(-1)).to(device))\n",
    "    soft_mask = exp.node_imp.detach().cpu()\n",
    "    r['soft_mask'] = soft_mask\n",
    "    hard_masks = generate_hard_masks(soft_mask)\n",
    "    for sparsity, hard_mask in hard_masks:\n",
    "        sparsity=sparsity.item()\n",
    "        r['res'][sparsity] = calculate_fidelity(data, hard_mask, model)\n",
    "        r['res'][sparsity]['hard_mask'] = hard_mask\n",
    "    r['res_topk'] = {\n",
    "        1: calculate_fidelity_topk(data, soft_mask, model,1),\n",
    "        3: calculate_fidelity_topk(data, soft_mask, model,3),\n",
    "        5: calculate_fidelity_topk(data, soft_mask, model,5)\n",
    "    }\n",
    "    return r\n",
    "    \n",
    "ig_explainer_results = []\n",
    "for data in tqdm(test_dataset):\n",
    "    data = data.to(device)\n",
    "    data.x = data.x.float()\n",
    "    try:\n",
    "        r = explain_ig_explainer(model, data)\n",
    "        ig_explainer_results.append(r)\n",
    "    except: pass\n",
    "\n",
    "\n",
    "with open(f'post_hoc/{dataset_name}/{seed}/ig.pkl', 'wb') as f:\n",
    "    pickle.dump(ig_explainer_results, f)\n",
    "ig_explainer_results = pickle.load(open(f'post_hoc/{dataset_name}/{seed}/ig.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf8fe34-dfb2-4fab-81a4-f8da0f16811b",
   "metadata": {},
   "source": [
    "# GStarX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a0fa0f1-8a87-4e94-b866-fa8c617a6df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19 [00:00<?, ?it/s]/home/spideralessio/.conda/envs/imp/lib/python3.8/site-packages/torch_geometric/deprecation.py:12: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "100%|██████████| 19/19 [00:28<00:00,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for data in test_dataset:\n",
    "    try:\n",
    "        data.to(device)\n",
    "        data.x = data.x.float()\n",
    "        pred = model(data.x.float(), data.edge_index).softmax(-1)\n",
    "        preds += [pred]\n",
    "    except: pass\n",
    "preds = torch.concat(preds)\n",
    "payoff_avg = preds.mean(0).tolist()\n",
    "gstarx = GStarX(model, device, payoff_avg=payoff_avg)\n",
    "gstarx_explainer_results = []\n",
    "\n",
    "for data in tqdm(test_dataset):\n",
    "    try:\n",
    "        data = data.to(device)\n",
    "        data.x = data.x.float()\n",
    "        r = {\n",
    "            'data': data,\n",
    "            'pred': model(data.x.float(), data.edge_index).softmax(-1).detach().cpu().numpy(),\n",
    "            'res':{}\n",
    "        }\n",
    "        soft_mask = torch.tensor(gstarx.explain(data, superadditive_ext=False, num_samples=5))\n",
    "        r['soft_mask'] = soft_mask\n",
    "        hard_masks = generate_hard_masks(soft_mask)\n",
    "        for sparsity, hard_mask in hard_masks:\n",
    "            # print(sparsity)\n",
    "            r['res'][sparsity.item()] = calculate_fidelity(data, hard_mask, model)\n",
    "            r['res'][sparsity.item()]['hard_mask'] = hard_mask\n",
    "        r['res_topk'] = {\n",
    "            1: calculate_fidelity_topk(data, soft_mask, model,1),\n",
    "            3: calculate_fidelity_topk(data, soft_mask, model,3),\n",
    "            5: calculate_fidelity_topk(data, soft_mask, model,5)\n",
    "        }\n",
    "        gstarx_explainer_results.append(r)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "with open(f'post_hoc/{dataset_name}/{seed}/gstarx.pkl', 'wb') as f:\n",
    "    pickle.dump(gstarx_explainer_results, f)\n",
    "gstarx_explainer_results = pickle.load(open(f'post_hoc/{dataset_name}/{seed}/gstarx.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c0f73d-c2ef-4a8c-a144-328ea89ca520",
   "metadata": {},
   "source": [
    "# SubGraphX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10187eed-deef-49dd-9b1d-26c39364c6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [01:40<00:00,  5.28s/it]\n"
     ]
    }
   ],
   "source": [
    "from graphxai.explainers import SubgraphX\n",
    "subgraphx_explainer = SubgraphX(model, sample_num=10)\n",
    "\n",
    "subgraphx_explainer_results = []\n",
    "for data in tqdm(test_dataset):\n",
    "    try:\n",
    "        data = data.to(device)\n",
    "        data.x = data.x.float()\n",
    "        r = {\n",
    "            'data': data,\n",
    "            'pred': model(data.x.float(), data.edge_index).softmax(-1).detach().cpu().numpy(),\n",
    "            'res':{}\n",
    "        }\n",
    "        exp = subgraphx_explainer.get_explanation_graph(x=data.x.float(), edge_index=data.edge_index, label=torch.tensor(r['pred'].argmax(-1)))\n",
    "        soft_mask = exp.node_imp\n",
    "        r['soft_mask'] = soft_mask\n",
    "        hard_masks = generate_hard_masks(soft_mask)\n",
    "        for sparsity, hard_mask in hard_masks:\n",
    "            # print(sparsity)\n",
    "            r['res'][sparsity.item()] = calculate_fidelity(data, hard_mask, model)\n",
    "            r['res'][sparsity.item()]['hard_mask'] = hard_mask\n",
    "        r['res_topk'] = {\n",
    "            1: calculate_fidelity_topk(data, soft_mask, model,1),\n",
    "            3: calculate_fidelity_topk(data, soft_mask, model,3),\n",
    "            5: calculate_fidelity_topk(data, soft_mask, model,5)\n",
    "        }\n",
    "    except: \n",
    "        continue\n",
    "    subgraphx_explainer_results.append(r)\n",
    "\n",
    "\n",
    "with open(f'post_hoc/{dataset_name}/{seed}/subgraphx.pkl', 'wb') as f:\n",
    "    pickle.dump(subgraphx_explainer_results, f)\n",
    "subgraphx_explainer_results = pickle.load(open(f'post_hoc/{dataset_name}/{seed}/subgraphx.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d925d26-0574-411e-bb8d-695a8099fe50",
   "metadata": {},
   "source": [
    "# LogiX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "051c80d3-68f2-495c-a3fd-722e1101bb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 75.15151733398437 0.33333333333333337 0.3684210526315789 0.3157894736842105 tensor(712, device='cuda:0')\n",
      "10 73.50275146484375 0.33333333333333337 0.3684210526315789 0.3157894736842105 tensor(688, device='cuda:0')\n",
      "20 71.27392781575521 0.3333333333333333 0.3684210526315789 0.3157894736842105 tensor(677, device='cuda:0')\n",
      "30 67.9484770711263 0.33333333333333337 0.3684210526315789 0.3157894736842105 tensor(666, device='cuda:0')\n",
      "40 63.7150765991211 0.33333333333333337 0.3684210526315789 0.3157894736842105 tensor(662, device='cuda:0')\n",
      "50 59.62910196940104 0.3333333333333333 0.3684210526315789 0.3157894736842105 tensor(656, device='cuda:0')\n",
      "60 56.259444885253906 0.33333333333333337 0.3684210526315789 0.3157894736842105 tensor(647, device='cuda:0')\n",
      "70 25.23301063537598 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(627, device='cuda:0')\n",
      "80 24.83815897623698 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(616, device='cuda:0')\n",
      "90 9.92570612589518 0.3333333333333333 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "100 9.923855781555176 0.3333333333333333 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "110 9.921852111816406 0.33333333333333337 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "120 9.919998995463052 0.34 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "130 9.91685614267985 0.3333333333333333 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "140 9.912840932210289 0.34 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "150 9.909619267781574 0.33999999999999997 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "160 9.909946619669597 0.32 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "170 9.90482250213623 0.3400000000000001 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "180 9.901668090820312 0.3266666666666667 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "190 9.89746011098226 0.32666666666666666 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "200 9.894328702290853 0.32666666666666666 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "210 9.889845759073893 0.3333333333333333 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "220 9.885118382771811 0.33999999999999997 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "230 9.879783528645833 0.33333333333333337 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "240 9.877010358174642 0.33333333333333337 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "250 9.87202220916748 0.3266666666666667 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "260 9.866471684773762 0.32666666666666666 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "270 9.859295260111491 0.32666666666666666 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "280 9.851394144694009 0.32666666666666666 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "290 9.841777725219726 0.3333333333333333 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "300 9.834890314737956 0.33333333333333337 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "310 9.829753061930338 0.32666666666666666 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "320 9.821121966044107 0.33333333333333326 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "330 9.813062718709308 0.3333333333333333 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "340 9.807649688720703 0.32 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "350 9.799040451049803 0.32666666666666666 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "360 9.788904495239258 0.37333333333333335 0.3684210526315789 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "370 9.779490051269532 0.34 0.42105263157894735 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "380 9.768629697163899 0.38666666666666666 0.42105263157894735 0.3684210526315789 tensor(597, device='cuda:0')\n",
      "390 9.757643864949543 0.45333333333333337 0.5263157894736842 0.3157894736842105 tensor(597, device='cuda:0')\n",
      "400 9.749425748189292 0.47333333333333333 0.5263157894736842 0.3684210526315789 tensor(597, device='cuda:0')\n",
      "410 9.738249867757162 0.4733333333333334 0.631578947368421 0.3684210526315789 tensor(597, device='cuda:0')\n",
      "420 9.726111984252928 0.4933333333333334 0.5789473684210527 0.42105263157894735 tensor(597, device='cuda:0')\n",
      "430 9.711091512044272 0.5066666666666667 0.5789473684210527 0.42105263157894735 tensor(595, device='cuda:0')\n",
      "440 9.701179428100586 0.5133333333333334 0.5789473684210527 0.3684210526315789 tensor(595, device='cuda:0')\n",
      "450 9.686590677897136 0.5066666666666667 0.631578947368421 0.5263157894736842 tensor(595, device='cuda:0')\n",
      "460 9.671769205729166 0.5666666666666667 0.631578947368421 0.47368421052631576 tensor(595, device='cuda:0')\n",
      "470 9.65600254058838 0.58 0.631578947368421 0.47368421052631576 tensor(593, device='cuda:0')\n",
      "480 9.639634755452473 0.56 0.6842105263157895 0.47368421052631576 tensor(593, device='cuda:0')\n",
      "490 9.625352363586424 0.6466666666666667 0.7368421052631579 0.47368421052631576 tensor(593, device='cuda:0')\n",
      "500 9.605490290323893 0.5866666666666667 0.6842105263157895 0.47368421052631576 tensor(593, device='cuda:0')\n",
      "510 9.590210151672363 0.5533333333333335 0.6842105263157895 0.42105263157894735 tensor(593, device='cuda:0')\n",
      "520 9.568727747599283 0.6 0.6842105263157895 0.3684210526315789 tensor(593, device='cuda:0')\n",
      "530 9.550243555704752 0.6066666666666667 0.631578947368421 0.3684210526315789 tensor(593, device='cuda:0')\n",
      "540 9.517486534118655 0.5666666666666665 0.5789473684210527 0.3684210526315789 tensor(593, device='cuda:0')\n",
      "550 9.460621376037599 0.6200000000000001 0.5789473684210527 0.42105263157894735 tensor(593, device='cuda:0')\n",
      "560 9.43597869873047 0.64 0.5789473684210527 0.47368421052631576 tensor(593, device='cuda:0')\n",
      "570 9.410915959676107 0.6266666666666666 0.5789473684210527 0.47368421052631576 tensor(593, device='cuda:0')\n",
      "580 9.38427947998047 0.6533333333333333 0.5789473684210527 0.5263157894736842 tensor(593, device='cuda:0')\n",
      "590 9.341909154256184 0.6533333333333333 0.5263157894736842 0.5789473684210527 tensor(593, device='cuda:0')\n",
      "600 9.313921229044595 0.66 0.5789473684210527 0.5789473684210527 tensor(592, device='cuda:0')\n",
      "610 9.283762029012044 0.6599999999999999 0.5789473684210527 0.6842105263157895 tensor(592, device='cuda:0')\n",
      "620 9.252215983072917 0.6599999999999999 0.631578947368421 0.6842105263157895 tensor(592, device='cuda:0')\n",
      "630 9.214362258911132 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(592, device='cuda:0')\n",
      "640 9.0775510152181 0.6733333333333335 0.5789473684210527 0.7368421052631579 tensor(592, device='cuda:0')\n",
      "650 8.925377477010091 0.6599999999999999 0.5789473684210527 0.631578947368421 tensor(592, device='cuda:0')\n",
      "660 8.859806264241536 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(592, device='cuda:0')\n",
      "670 8.795083287556965 0.6733333333333335 0.631578947368421 0.6842105263157895 tensor(591, device='cuda:0')\n",
      "680 8.755331077575683 0.6666666666666667 0.631578947368421 0.6842105263157895 tensor(591, device='cuda:0')\n",
      "690 8.674569079081218 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(591, device='cuda:0')\n",
      "700 8.624186579386395 0.6666666666666667 0.631578947368421 0.6842105263157895 tensor(591, device='cuda:0')\n",
      "710 8.554171473185223 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(591, device='cuda:0')\n",
      "720 8.502277539571125 0.6666666666666667 0.631578947368421 0.6842105263157895 tensor(591, device='cuda:0')\n",
      "730 8.268265736897787 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(591, device='cuda:0')\n",
      "740 8.016311696370444 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(591, device='cuda:0')\n",
      "750 7.950822029113768 0.6666666666666667 0.631578947368421 0.6842105263157895 tensor(591, device='cuda:0')\n",
      "760 7.884675954182941 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(591, device='cuda:0')\n",
      "770 7.766069615681966 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(591, device='cuda:0')\n",
      "780 7.675089975992838 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(591, device='cuda:0')\n",
      "790 7.548927853902182 0.6666666666666667 0.631578947368421 0.6842105263157895 tensor(590, device='cuda:0')\n",
      "800 7.2034412765502935 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(590, device='cuda:0')\n",
      "810 4.939476979573568 0.6666666666666667 0.631578947368421 0.6842105263157895 tensor(589, device='cuda:0')\n",
      "820 4.784210879007976 0.6666666666666667 0.631578947368421 0.6842105263157895 tensor(589, device='cuda:0')\n",
      "830 4.683735243479411 0.6666666666666667 0.631578947368421 0.6842105263157895 tensor(588, device='cuda:0')\n",
      "840 4.584268709818522 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(588, device='cuda:0')\n",
      "850 4.447180620829265 0.6666666666666667 0.631578947368421 0.6842105263157895 tensor(588, device='cuda:0')\n",
      "860 4.267058925628662 0.6666666666666667 0.631578947368421 0.6842105263157895 tensor(588, device='cuda:0')\n",
      "870 4.0782835578918455 0.6666666666666667 0.631578947368421 0.6842105263157895 tensor(587, device='cuda:0')\n",
      "880 3.9070108350118002 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(586, device='cuda:0')\n",
      "890 3.7358075777689614 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(585, device='cuda:0')\n",
      "900 3.404672040939331 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(584, device='cuda:0')\n",
      "910 2.7802740653355915 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(584, device='cuda:0')\n",
      "920 2.5011114247639976 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(583, device='cuda:0')\n",
      "930 2.409706042607625 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(582, device='cuda:0')\n",
      "940 2.3404346338907875 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(582, device='cuda:0')\n",
      "950 2.2586929893493655 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(581, device='cuda:0')\n",
      "960 2.0269071165720622 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(581, device='cuda:0')\n",
      "970 1.4079534435272218 0.6666666666666666 0.631578947368421 0.6842105263157895 tensor(581, device='cuda:0')\n",
      "980 1.378244663874308 0.6733333333333332 0.631578947368421 0.6842105263157895 tensor(580, device='cuda:0')\n",
      "990 1.3657230218251544 0.6666666666666665 0.631578947368421 0.6842105263157895 tensor(580, device='cuda:0')\n",
      "1000 1.3591700569788612 0.6733333333333333 0.631578947368421 0.6842105263157895 tensor(580, device='cuda:0')\n",
      "1010 1.3467484219868977 0.6733333333333332 0.631578947368421 0.6842105263157895 tensor(580, device='cuda:0')\n",
      "1020 1.3519945462544758 0.6666666666666667 0.631578947368421 0.6842105263157895 tensor(579, device='cuda:0')\n",
      "1030 1.332978986104329 0.6733333333333333 0.631578947368421 0.6842105263157895 tensor(579, device='cuda:0')\n",
      "1040 1.3295814196268718 0.6733333333333332 0.631578947368421 0.6842105263157895 tensor(578, device='cuda:0')\n",
      "1050 1.3207945473988851 0.6733333333333333 0.631578947368421 0.6842105263157895 tensor(578, device='cuda:0')\n",
      "1060 1.3136403671900432 0.6733333333333335 0.631578947368421 0.6842105263157895 tensor(578, device='cuda:0')\n",
      "1070 1.329349112510681 0.6733333333333333 0.631578947368421 0.6842105263157895 tensor(576, device='cuda:0')\n",
      "1080 1.3134808683395387 0.6733333333333332 0.631578947368421 0.6842105263157895 tensor(576, device='cuda:0')\n",
      "1090 1.312876370747884 0.6733333333333333 0.631578947368421 0.6842105263157895 tensor(572, device='cuda:0')\n",
      "1100 1.2954757261276248 0.6733333333333333 0.631578947368421 0.6842105263157895 tensor(570, device='cuda:0')\n",
      "1110 1.2902911281585694 0.6733333333333333 0.631578947368421 0.6842105263157895 tensor(569, device='cuda:0')\n",
      "1120 1.2838559436798096 0.6733333333333333 0.631578947368421 0.6842105263157895 tensor(567, device='cuda:0')\n",
      "1130 1.292070698738098 0.6733333333333333 0.631578947368421 0.6842105263157895 tensor(566, device='cuda:0')\n",
      "1140 1.2896167596181232 0.6733333333333332 0.631578947368421 0.6842105263157895 tensor(564, device='cuda:0')\n",
      "1150 1.2697167174021402 0.6799999999999999 0.5789473684210527 0.6842105263157895 tensor(564, device='cuda:0')\n",
      "1160 1.2536110750834146 0.7133333333333333 0.631578947368421 0.631578947368421 tensor(563, device='cuda:0')\n",
      "1170 1.2663345750172932 0.7133333333333334 0.631578947368421 0.6842105263157895 tensor(560, device='cuda:0')\n",
      "1180 1.2418046474456788 0.7133333333333332 0.631578947368421 0.7368421052631579 tensor(560, device='cuda:0')\n",
      "1190 1.2457296021779378 0.74 0.631578947368421 0.7894736842105263 tensor(559, device='cuda:0')\n",
      "1200 1.2367713324228924 0.7733333333333333 0.7368421052631579 0.7368421052631579 tensor(558, device='cuda:0')\n",
      "1210 1.2205679639180502 0.7666666666666667 0.7368421052631579 0.7894736842105263 tensor(557, device='cuda:0')\n",
      "1220 1.2214339605967202 0.7733333333333333 0.7368421052631579 0.8421052631578947 tensor(556, device='cuda:0')\n",
      "1230 1.2170436350504557 0.7999999999999999 0.7368421052631579 0.8421052631578947 tensor(554, device='cuda:0')\n",
      "1240 1.2206324815750125 0.7666666666666667 0.7368421052631579 0.8421052631578947 tensor(553, device='cuda:0')\n",
      "1250 1.2107901589075725 0.7933333333333333 0.7368421052631579 0.7894736842105263 tensor(553, device='cuda:0')\n",
      "1260 1.2099895286560058 0.7800000000000001 0.7368421052631579 0.7894736842105263 tensor(553, device='cuda:0')\n",
      "1270 1.1988676007588703 0.7866666666666667 0.7368421052631579 0.7894736842105263 tensor(550, device='cuda:0')\n",
      "1280 1.1990633249282836 0.7999999999999999 0.7368421052631579 0.8421052631578947 tensor(547, device='cuda:0')\n",
      "1290 1.197711191177368 0.8133333333333332 0.7368421052631579 0.7894736842105263 tensor(543, device='cuda:0')\n",
      "1300 1.1994580396016439 0.7866666666666667 0.7368421052631579 0.7894736842105263 tensor(541, device='cuda:0')\n",
      "1310 1.2081622664133709 0.7733333333333333 0.6842105263157895 0.8421052631578947 tensor(540, device='cuda:0')\n",
      "1320 1.1924339803059896 0.78 0.7368421052631579 0.8421052631578947 tensor(538, device='cuda:0')\n",
      "1330 1.1898422129948933 0.7933333333333332 0.7368421052631579 0.7894736842105263 tensor(537, device='cuda:0')\n",
      "1340 1.1919992621739706 0.8066666666666666 0.7368421052631579 0.7894736842105263 tensor(536, device='cuda:0')\n",
      "1350 1.1925502840677895 0.8200000000000001 0.7894736842105263 0.8421052631578947 tensor(536, device='cuda:0')\n",
      "1360 1.1834956987698872 0.7866666666666666 0.7368421052631579 0.7894736842105263 tensor(534, device='cuda:0')\n",
      "1370 1.1892496411005655 0.8400000000000001 0.7894736842105263 0.8421052631578947 tensor(534, device='cuda:0')\n",
      "1380 1.1632673406600953 0.8066666666666668 0.7894736842105263 0.8421052631578947 tensor(532, device='cuda:0')\n",
      "1390 1.1730990346272785 0.7933333333333334 0.7368421052631579 0.7894736842105263 tensor(530, device='cuda:0')\n",
      "1400 1.1638608996073405 0.7999999999999999 0.7894736842105263 0.8421052631578947 tensor(527, device='cuda:0')\n",
      "1410 1.1431817022959392 0.8133333333333334 0.7894736842105263 0.8421052631578947 tensor(527, device='cuda:0')\n",
      "1420 1.1554315455754598 0.8066666666666668 0.7894736842105263 0.8421052631578947 tensor(526, device='cuda:0')\n",
      "1430 1.1461651881535848 0.8133333333333335 0.7894736842105263 0.8421052631578947 tensor(523, device='cuda:0')\n",
      "1440 1.1397617483139038 0.8266666666666667 0.7894736842105263 0.8421052631578947 tensor(522, device='cuda:0')\n",
      "1450 1.15965123017629 0.7933333333333333 0.7368421052631579 0.8421052631578947 tensor(519, device='cuda:0')\n",
      "1460 1.1477406644821166 0.8133333333333334 0.7368421052631579 0.8421052631578947 tensor(519, device='cuda:0')\n",
      "1470 1.1540554682413735 0.8266666666666668 0.7368421052631579 0.8421052631578947 tensor(519, device='cuda:0')\n",
      "1480 1.1386426067352295 0.8266666666666668 0.7368421052631579 0.8421052631578947 tensor(516, device='cuda:0')\n",
      "1490 1.1257724316914877 0.84 0.7368421052631579 0.8421052631578947 tensor(515, device='cuda:0')\n",
      "1500 1.1341680049896241 0.8266666666666668 0.7368421052631579 0.8421052631578947 tensor(513, device='cuda:0')\n",
      "1510 1.1227157243092853 0.8333333333333334 0.7894736842105263 0.8421052631578947 tensor(513, device='cuda:0')\n",
      "1520 1.1327210752169292 0.8466666666666668 0.7368421052631579 0.8421052631578947 tensor(513, device='cuda:0')\n",
      "1530 1.1094758733113605 0.8333333333333334 0.7894736842105263 0.8421052631578947 tensor(511, device='cuda:0')\n",
      "1540 1.0961552667617798 0.8533333333333333 0.7894736842105263 0.8421052631578947 tensor(511, device='cuda:0')\n",
      "1550 1.0779186471303304 0.8533333333333334 0.7894736842105263 0.8421052631578947 tensor(508, device='cuda:0')\n",
      "1560 1.0463521321614584 0.8666666666666667 0.7368421052631579 0.8421052631578947 tensor(508, device='cuda:0')\n",
      "1570 1.0442719284693398 0.88 0.7368421052631579 0.8421052631578947 tensor(508, device='cuda:0')\n",
      "1580 1.028379691441854 0.8933333333333334 0.7894736842105263 0.7894736842105263 tensor(507, device='cuda:0')\n",
      "1590 1.0079409408569335 0.8933333333333334 0.8947368421052632 0.7894736842105263 tensor(504, device='cuda:0')\n",
      "1600 0.9928043023745219 0.8999999999999999 0.8947368421052632 0.7894736842105263 tensor(502, device='cuda:0')\n",
      "1610 0.9800429598490398 0.9066666666666667 0.8947368421052632 0.7894736842105263 tensor(500, device='cuda:0')\n",
      "1620 0.9498339986801148 0.9066666666666668 0.8947368421052632 0.7894736842105263 tensor(499, device='cuda:0')\n",
      "1630 0.9431735626856487 0.9066666666666667 0.8947368421052632 0.7894736842105263 tensor(495, device='cuda:0')\n",
      "1640 0.9473610464731853 0.9133333333333333 0.8947368421052632 0.7894736842105263 tensor(492, device='cuda:0')\n",
      "1650 0.9548425157864888 0.9066666666666667 0.8947368421052632 0.7894736842105263 tensor(492, device='cuda:0')\n",
      "1660 0.9494995005925495 0.8933333333333332 0.8947368421052632 0.7894736842105263 tensor(490, device='cuda:0')\n",
      "1670 0.9203603855768838 0.8999999999999999 0.8947368421052632 0.7894736842105263 tensor(486, device='cuda:0')\n",
      "1680 0.9231973807017008 0.9066666666666667 0.8947368421052632 0.7894736842105263 tensor(480, device='cuda:0')\n",
      "1690 0.9318072891235353 0.9066666666666667 0.8947368421052632 0.7894736842105263 tensor(478, device='cuda:0')\n",
      "1700 0.9179697036743164 0.9066666666666667 0.8947368421052632 0.7894736842105263 tensor(476, device='cuda:0')\n",
      "1710 0.9336949888865153 0.9066666666666666 0.8947368421052632 0.7894736842105263 tensor(475, device='cuda:0')\n",
      "1720 0.9200120282173158 0.9066666666666666 0.8947368421052632 0.7894736842105263 tensor(474, device='cuda:0')\n",
      "1730 0.9080131689707439 0.9066666666666666 0.8947368421052632 0.7894736842105263 tensor(469, device='cuda:0')\n",
      "1740 0.9038251034418743 0.9133333333333333 0.8947368421052632 0.7894736842105263 tensor(464, device='cuda:0')\n",
      "1750 0.9026382263501485 0.9200000000000002 0.8947368421052632 0.7894736842105263 tensor(457, device='cuda:0')\n",
      "1760 0.9085489400227865 0.9000000000000001 0.8947368421052632 0.7894736842105263 tensor(450, device='cuda:0')\n",
      "1770 0.9108710209528605 0.9000000000000001 0.8947368421052632 0.7894736842105263 tensor(434, device='cuda:0')\n",
      "1780 0.9022996997833251 0.9066666666666666 0.8947368421052632 0.7894736842105263 tensor(430, device='cuda:0')\n",
      "1790 0.863801261583964 0.9400000000000001 0.8947368421052632 0.7894736842105263 tensor(425, device='cuda:0')\n",
      "1800 0.8862690734863281 0.8933333333333333 0.8947368421052632 0.7894736842105263 tensor(420, device='cuda:0')\n",
      "1810 0.8399865516026814 0.9266666666666667 0.8947368421052632 0.7894736842105263 tensor(398, device='cuda:0')\n",
      "1820 0.855203439394633 0.92 0.9473684210526315 0.7894736842105263 tensor(372, device='cuda:0')\n",
      "1830 0.8715501411755879 0.9066666666666666 0.9473684210526315 0.7894736842105263 tensor(362, device='cuda:0')\n",
      "1840 0.8423687998453777 0.92 0.9473684210526315 0.7894736842105263 tensor(357, device='cuda:0')\n",
      "1850 0.8541433493296305 0.9133333333333333 0.9473684210526315 0.7894736842105263 tensor(351, device='cuda:0')\n",
      "1860 0.8566925032933552 0.9066666666666667 0.9473684210526315 0.7894736842105263 tensor(336, device='cuda:0')\n",
      "1870 0.8344364245732625 0.9133333333333334 0.9473684210526315 0.7894736842105263 tensor(304, device='cuda:0')\n",
      "1880 0.8256014903386434 0.9066666666666667 0.9473684210526315 0.7894736842105263 tensor(295, device='cuda:0')\n",
      "1890 0.829600579738617 0.9133333333333333 0.9473684210526315 0.7894736842105263 tensor(281, device='cuda:0')\n",
      "1900 0.837560272216797 0.9133333333333332 0.9473684210526315 0.7894736842105263 tensor(271, device='cuda:0')\n",
      "1910 0.8307225799560547 0.9266666666666667 0.9473684210526315 0.7894736842105263 tensor(266, device='cuda:0')\n",
      "1920 0.8070099814732868 0.9266666666666666 0.9473684210526315 0.7894736842105263 tensor(260, device='cuda:0')\n",
      "1930 0.811759413878123 0.92 0.9473684210526315 0.7894736842105263 tensor(252, device='cuda:0')\n",
      "1940 0.8167232775688171 0.9200000000000002 0.9473684210526315 0.7894736842105263 tensor(243, device='cuda:0')\n",
      "1950 0.8105699904759724 0.9199999999999999 0.9473684210526315 0.7894736842105263 tensor(237, device='cuda:0')\n",
      "1960 0.8209186347325643 0.9066666666666667 0.9473684210526315 0.7894736842105263 tensor(236, device='cuda:0')\n",
      "1970 0.8065150411923726 0.9200000000000002 0.9473684210526315 0.7894736842105263 tensor(230, device='cuda:0')\n",
      "1980 0.8112967864672344 0.9266666666666666 0.9473684210526315 0.7894736842105263 tensor(225, device='cuda:0')\n",
      "1990 0.7833058977127076 0.9266666666666666 0.9473684210526315 0.7894736842105263 tensor(221, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:45<00:00,  2.39s/it]\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model_tell, loader, device, optimizer, num_classes, reg=1, sqrt_reg=False):\n",
    "    model_tell.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for data in loader:\n",
    "        try:\n",
    "            loss = 0\n",
    "            if data.x is None:\n",
    "                data.x = torch.ones((data.num_nodes, model_tell.num_features))\n",
    "            if data.y.numel() == 0: continue\n",
    "            if data.x.isnan().any(): continue\n",
    "            if data.y.isnan().any(): continue\n",
    "            data.x = data.x.float()\n",
    "            y = data.y.reshape(-1).to(device).long()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = model_tell(data.x.float().to(device), data.edge_index.to(device), data.batch.to(device))       \n",
    "            pred = out.argmax(-1)\n",
    "            loss += F.binary_cross_entropy(out.reshape(-1), torch.nn.functional.one_hot(y, num_classes=num_classes).float().reshape(-1)) + F.nll_loss(F.log_softmax(out, dim=-1), y.long())\n",
    "            # loss += reg*(torch.sqrt(torch.clamp(model_tell.fc.weight, min=1e-5)).sum(-1).mean() + model_tell.fc.phi_in.entropy)\n",
    "            loss += reg*model_tell.fc.phi_in.entropy\n",
    "            if sqrt_reg:\n",
    "                loss+= reg*torch.sqrt(torch.clamp(model_tell.fc.weight, min=1e-5)).sum(-1).mean()\n",
    "            else:\n",
    "                loss+=reg*model_tell.fc.reg_loss\n",
    "            loss.backward()\n",
    "            zero_nan_gradients(model_tell)#torch.sqrt(torch.clamp(model_tell.fc.weight, min=1e-5)).sum(-1).mean()  + \n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * data.num_graphs / len(loader.dataset)\n",
    "            total_correct += pred.eq(y).sum().item() / len(loader.dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "\n",
    "    return total_loss, total_correct\n",
    "\n",
    "model_tell = GIN(num_classes=num_classes, num_features=num_features, num_layers=num_layers, hidden_dim=hidden_dim)\n",
    "model_tell.load_state_dict(torch.load(os.path.join(results_path, 'best.pt'), map_location=device))\n",
    "model_tell = model_tell.to(device)\n",
    "\n",
    "\n",
    "\n",
    "model_tell.fc = LogicalLayer(model_tell.fc1.in_features, num_classes).to(device)\n",
    "model_tell.fc.phi_in.tau = 10\n",
    "\n",
    "def forward_tell(self):\n",
    "    def fwd(x, edge_index, batch=None, activations=False, *args, **kwargs):\n",
    "        if batch is None:\n",
    "            batch = torch.zeros(x.shape[0]).long().to(x.device)\n",
    "        xs = []\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            xs.append(x)\n",
    "            x = self.dropout(x)\n",
    "    \n",
    "        x_mean = global_mean_pool(torch.hstack(xs), batch)\n",
    "        x_max = global_max_pool(torch.hstack(xs), batch)\n",
    "        x_sum = global_add_pool(torch.hstack(xs), batch)\n",
    "        x = torch.hstack([x_mean, x_max, x_sum])\n",
    "        # x = self.dropout(x)\n",
    "        acts = self.fc.phi_in(x)\n",
    "        x = self.fc(x)\n",
    "        if activations:\n",
    "            return x, acts, xs\n",
    "        return x\n",
    "    return fwd\n",
    "\n",
    "\n",
    "model_tell.forward = forward_tell(model_tell)\n",
    "model_tell.fc.phi_in.w.shape\n",
    "optimizer = torch.optim.Adam(model_tell.fc.parameters(), lr=0.001, weight_decay=0)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "for i in range(2000):\n",
    "    train_loss, train_acc = train_epoch(model_tell, train_loader, device, optimizer, num_classes, reg=0.1 if i<=800 else 0.01, sqrt_reg=i>800)\n",
    "    val_acc = test_epoch(model_tell, val_loader, device)\n",
    "    test_acc = test_epoch(model_tell, test_loader, device)\n",
    "    if i%10 == 0:\n",
    "        print(i, train_loss, train_acc, val_acc, test_acc, (model_tell.fc.weight>1e-4).sum())\n",
    "\n",
    "\n",
    "model_tell.forward = forward_tell(model_tell)\n",
    "\n",
    "\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "feat_map = []\n",
    "for readout in ['mean', 'max', 'sum']:\n",
    "    for l in range(num_layers):\n",
    "        for d in range(hidden_dim):\n",
    "            feat_map.append((readout, l, d))\n",
    "\n",
    "tell_explainer_results = []\n",
    "for data in tqdm(test_dataset):\n",
    "    try:\n",
    "        data = data.to(device)\n",
    "        data.x = data.x.float()\n",
    "        pred_tell, rule_acts, layers_acts = model_tell(data.x.float(), data.edge_index, activations=True)\n",
    "        \n",
    "        pred = model(data.x.float(), data.edge_index)\n",
    "        r = {\n",
    "            'data': data,\n",
    "            'pred': pred.softmax(-1).detach().cpu().numpy(),\n",
    "            'res':{}\n",
    "        }\n",
    "        pred_c = r['pred'].argmax(-1).item()\n",
    "        rules = extract_rules(model_tell.fc)\n",
    "        soft_mask = torch.zeros(data.x.shape[0]).to(device)\n",
    "        for c, class_rules in enumerate(rules):\n",
    "            for rule in class_rules:\n",
    "                for literal in rule:\n",
    "                    agg, layer, i = feat_map[literal]\n",
    "                    acts = layers_acts[layer][:,i]\n",
    "                    m = torch.zeros_like(soft_mask)\n",
    "                    if agg == 'max':\n",
    "                        m[acts>=acts.max()] = (1 if pred_c==c else -1)*acts.max()*rule_acts[:,literal].item()*model_tell.fc.weight[c,literal]\n",
    "                    elif agg == 'sum':\n",
    "                        m=(1 if pred_c==c else -1)*acts*rule_acts[:,literal].item()*model_tell.fc.weight[c,literal]\n",
    "                    else:\n",
    "                        m=(1 if pred_c==c else -1)*acts*rule_acts[:,literal].item()*model_tell.fc.weight[c,literal]\n",
    "                    m_=torch.zeros_like(m)\n",
    "                    for i in range(len(m)):\n",
    "                        if m[i] > 0:\n",
    "                            try:\n",
    "                                subset, _, _, _ = k_hop_subgraph(i, 1, data.edge_index.cpu())\n",
    "                                m_[subset] += m[i]\n",
    "                            except:\n",
    "                                m_[i] = m[i]\n",
    "                    soft_mask+=m_    \n",
    "\n",
    "        # print(soft_mask)\n",
    "        soft_mask = soft_mask.detach().cpu()\n",
    "        r['soft_mask'] = soft_mask\n",
    "        hard_masks = generate_hard_masks(soft_mask)\n",
    "        for sparsity, hard_mask in hard_masks:\n",
    "            sparsity = sparsity.item()\n",
    "            r['res'][sparsity] = calculate_fidelity(data, hard_mask, model)\n",
    "            r['res'][sparsity]['hard_mask'] = hard_mask\n",
    "        r['res_topk'] = {\n",
    "            1: calculate_fidelity_topk(data, soft_mask, model,1),\n",
    "            3: calculate_fidelity_topk(data, soft_mask, model,3),\n",
    "            5: calculate_fidelity_topk(data, soft_mask, model,5)\n",
    "        }\n",
    "        tell_explainer_results.append(r)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "model_tell.forward = None\n",
    "\n",
    "with open(f'post_hoc/{dataset_name}/{seed}/tell_model.pkl', 'wb') as f:\n",
    "    pickle.dump(model_tell, f)\n",
    "\n",
    "\n",
    "with open(f'post_hoc/{dataset_name}/{seed}/tell.pkl', 'wb') as f:\n",
    "    pickle.dump(tell_explainer_results, f)\n",
    "torch.save(model_tell, f'post_hoc/{dataset_name}/{seed}/model_tell.pt')\n",
    "tell_explainer_results = pickle.load(open(f'post_hoc/{dataset_name}/{seed}/tell.pkl', 'rb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-imp]",
   "language": "python",
   "name": "conda-env-.conda-imp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
